{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ban đầu: \n",
      " [[[ 2.24993798  0.93003304  0.64636707 -0.16226251]\n",
      "  [-0.14318004  0.35855661  1.06733834  1.53455477]\n",
      "  [-0.486989    1.47998358 -0.15091206 -1.05794049]\n",
      "  [ 0.6594266  -0.17006548  1.80552295  1.55287562]\n",
      "  [ 1.33808956 -0.74990166  0.21630472 -0.45453599]]\n",
      "\n",
      " [[ 0.65699609 -0.28014326  0.1557733  -0.68552987]\n",
      "  [ 0.99961896 -1.51971721  0.23570077  0.35635283]\n",
      "  [ 0.0224391   1.01097942  0.44795195  2.14752525]\n",
      "  [ 0.19138886  0.93224199 -1.40751126 -0.3284627 ]\n",
      "  [-0.14883641 -1.22249176  0.77987447  0.38287989]]]\n",
      "(2, 5, 4)\n",
      "\n",
      "Kết quả sau khi áp dụng RoPE:\n",
      " [[[ 2.24993798  0.93003304  0.64636707 -0.16226251]\n",
      "  [-0.37907549  0.07324711  1.05193968  1.54515125]\n",
      "  [-1.14308633 -1.05870833 -0.12972448 -1.06074694]\n",
      "  [-0.62882774  0.26142183  1.75813125  1.60633444]\n",
      "  [-1.44216116 -0.52250108  0.23430829 -0.44552253]]\n",
      "\n",
      " [[ 0.65699609 -0.28014326  0.1557733  -0.68552987]\n",
      "  [ 1.81889437  0.02004364  0.23212551  0.35869198]\n",
      "  [-0.92861895 -0.40031207  0.40491472  2.1560542 ]\n",
      "  [-0.32103153 -0.89590378 -1.39702552 -0.37053391]\n",
      "  [-0.82789885  0.91171371  0.76393954  0.41376029]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rotary_positional_embedding(x: np.ndarray, \n",
    "                              seq_len: int, \n",
    "                              embed_dim: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Áp dụng Rotary Positional Embedding cho vector ẩn.\n",
    "    \n",
    "    Args:\n",
    "        x: Tensor input (batch_size, seq_len, dim).\n",
    "        seq_len: Chiều dài chuỗi (sequence length).\n",
    "        dim: Kích thước vector (embedding dimension).\n",
    "        \n",
    "    Returns:\n",
    "        Tensor sau khi áp dụng RoPE.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Tách vector thành (even, odd)\n",
    "    x_even = x[:, :, 0::2]  # Các giá trị tại chỉ số chẵn\n",
    "    x_odd = x[:, :, 1::2]   # Các giá trị tại chỉ số lẻ\n",
    "\n",
    "\n",
    "    # 2. Tính góc xoay\n",
    "    positions = np.arange(start=0, stop=seq_len)[:, None] # # Vị trí từng token, shape: [seq_len, 1]\n",
    "    theta = np.arange(0, embed_dim, 2) / embed_dim # 2* k / d. Shape: [embed_dim / 2, ]\n",
    "    theta = 1 / (10000 ** (theta)) # 1 / (10000 ** (2 *k / d)). Shape: [embed_dim / 2, ]\n",
    "    # print(\"positions: \\n\", positions)\n",
    "    # print(\"theta: \\n\", theta)\n",
    "    angles = positions * theta # theta\n",
    "    # print(\"angles: \\n\", angles.shape)\n",
    "\n",
    "    # 3. Tính cos/sin của góc\n",
    "    cos_angles = np.cos(angles)\n",
    "    sin_angles = np.sin(angles)\n",
    "\n",
    "    # 4. Áp dụng phép xoay cho từng cặp\n",
    "    x_rotated_even = x_even * cos_angles - x_odd * sin_angles\n",
    "    x_rotated_odd = x_even * sin_angles + x_odd * cos_angles\n",
    "\n",
    "    # ghép lại\n",
    "    x_rotated = np.ones_like(x)\n",
    "    x_rotated[:, :, 0::2] = x_rotated_even\n",
    "    x_rotated[:, :, 1::2] = x_rotated_odd\n",
    "\n",
    "    return x_rotated\n",
    "\n",
    "N = 2\n",
    "seq_len = 5\n",
    "embed_dim = 4\n",
    "\n",
    "mock_data = np.random.randn(N, seq_len, embed_dim)\n",
    "\n",
    "# In dữ liệu gốc\n",
    "print(\"Input ban đầu: \\n\", mock_data)\n",
    "\n",
    "# Áp dụng RoPE\n",
    "x_rotated = rotary_positional_embedding(x=mock_data, seq_len=seq_len, embed_dim=embed_dim)\n",
    "\n",
    "# In kết quả\n",
    "print(x_rotated.shape)\n",
    "print(\"\\nKết quả sau khi áp dụng RoPE:\\n\",  x_rotated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ducpham/Documents/Pytorch-Coding/LLMs/LLama-2\n"
     ]
    }
   ],
   "source": [
    "%cd ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>label_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66b5aabf8a38820e82e0b6ce</td>\n",
       "      <td>Xu hướng</td>\n",
       "      <td>100+ STT Né thính, Cap né thính hài hước, NÉT ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66b5a9838a38820e82e0b64d</td>\n",
       "      <td>Xu hướng</td>\n",
       "      <td>Top 111+ stt cuộc sống an nhiên, bình dị tự tạ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66b5cb358a38820e82e0c408</td>\n",
       "      <td>Xu hướng</td>\n",
       "      <td>Top hạt giống hoa dễ trồng, nở quanh năm cho n...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66b5c7548a38820e82e0c271</td>\n",
       "      <td>Dinh dưỡng</td>\n",
       "      <td>Chi tiết 3 cách nấu rau bò khai đơn giản mà th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66b5c7a78a38820e82e0c294</td>\n",
       "      <td>Nhà</td>\n",
       "      <td>Top 10 quạt cây hơi nước được ưa chuộng nhất h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id       label  \\\n",
       "0  66b5aabf8a38820e82e0b6ce    Xu hướng   \n",
       "1  66b5a9838a38820e82e0b64d    Xu hướng   \n",
       "2  66b5cb358a38820e82e0c408    Xu hướng   \n",
       "3  66b5c7548a38820e82e0c271  Dinh dưỡng   \n",
       "4  66b5c7a78a38820e82e0c294         Nhà   \n",
       "\n",
       "                                               title  label_numeric  \n",
       "0  100+ STT Né thính, Cap né thính hài hước, NÉT ...              7  \n",
       "1  Top 111+ stt cuộc sống an nhiên, bình dị tự tạ...              7  \n",
       "2  Top hạt giống hoa dễ trồng, nở quanh năm cho n...              7  \n",
       "3  Chi tiết 3 cách nấu rau bò khai đơn giản mà th...              1  \n",
       "4  Top 10 quạt cây hơi nước được ưa chuộng nhất h...              4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train_set.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 1801, 3: 1435, 5: 433, 4: 286, 0: 241, 6: 192, 1: 84, 2: 41, 8: 30}\n",
      "{'Xu hướng': 1801, 'Làm Đẹp': 1435, 'Trẻ em': 433, 'Nhà': 286, 'Công Nghệ': 241, 'Tài chính': 192, 'Dinh dưỡng': 84, 'Khuyến mãi': 41, 'Đánh giá': 30}\n"
     ]
    }
   ],
   "source": [
    "print(dict(train_df['label_numeric'].value_counts()))\n",
    "print(dict(train_df['label'].value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, \n",
    "                 depth: int, # d_model // num_heads\n",
    "                 base: int = 10000):\n",
    "        super().__init__()\n",
    "        theta = 1.0 / (base ** (torch.arange(0, depth, 2) / depth)) # [embed_dim //2 ,]\n",
    "        self.register_buffer(name=\"theta\", tensor=theta)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: [N, num_heads, seq_len, depth] \n",
    "        # do seq_len kh cố định < tokenizer của gpt2 thiết kế cho chiều dài đông>, \n",
    "        # vì vậy ta sẽ tạo postions khi có seq_len đưuọc lấy từ x\n",
    "        seq_len = x.size(2) \n",
    "        positions = torch.arange(0, seq_len)[:, None]\n",
    "        # print(\"positions: \", positions.shape)\n",
    "        # print(\"theta: \", self.theta.shape)\n",
    "        theta_cp = positions * self.theta\n",
    "        x_even, x_odd = x[..., 0::2], x[..., 1::2] # [N, num_heads, seq_len, depth//2]\n",
    "        \n",
    "        sin_angles = torch.sin(theta_cp)\n",
    "        cos_angles = torch.cos(theta_cp)\n",
    "\n",
    "        x_even_rotated = x_even * cos_angles - x_odd * sin_angles\n",
    "        x_odd_rotated = x_even * sin_angles + x_odd * cos_angles\n",
    "\n",
    "        x_rotated = torch.ones_like(x)\n",
    "        x_rotated[..., 0::2] = x_even_rotated\n",
    "        x_rotated[..., 1::2] = x_odd_rotated\n",
    "\n",
    "        return x_rotated\n",
    " \n",
    "\n",
    "mock_data = torch.randint(0, 1, (1, 4, 4))\n",
    "embed_model = RotaryPositionalEmbedding(depth= 4//1)\n",
    "output = embed_model.forward(mock_data)\n",
    "print(\"output: \", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  torch.Size([1, 1000, 256])\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, \n",
    "                 num_heads: int, \n",
    "                 ff_dim: int, \n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.rotary_embed = RotaryPositionalEmbedding(depth = self.depth)\n",
    "        \n",
    "        self.Wq = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "        self.Wk = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "        self.Wv = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "\n",
    "        self.Wo = nn.Linear(in_features=d_model, out_features=d_model)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(in_features=d_model, out_features=ff_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(in_features=ff_dim, out_features=d_model)\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(normalized_shape=d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(normalized_shape=d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def split_heads(self, x: torch.Tensor, batch_size: int):\n",
    "        # [N, seq_len, embed_dim] -> [N, num_heads, seq_len, embed_dim//num_heads]\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        return x.transpose(1, 2)\n",
    "    \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask =None):\n",
    "        matmul_qk = torch.matmul(Q, K.transpose(-2, -1))\n",
    "        dk = torch.tensor(K.size(-1), dtype=torch.float32)\n",
    "        scaled_attention_logits = matmul_qk / torch.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits = scaled_attention_logits.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask = None):\n",
    "        # shape x: [N, seq_len, d_model]\n",
    "        batch_size = x.size(0)\n",
    "        # Apply linear layers and split into heads\n",
    "        Q = self.split_heads(x=self.Wq(x), batch_size=batch_size) # [N, num_heads, seq_len, depth]\n",
    "        K = self.split_heads(x=self.Wk(x), batch_size=batch_size) # [N, num_heads, seq_len, depth]\n",
    "        V = self.split_heads(x=self.Wv(x), batch_size=batch_size) # [N, num_heads, seq_len, depth]\n",
    "        # Rotary position embedding\n",
    "        Q_rotated = self.rotary_embed(Q) # [N, num_heads, seq_len, depth]\n",
    "        K_rotated = self.rotary_embed(K) # [N, num_heads, seq_len, depth]\n",
    "\n",
    "\n",
    "        # Apply the custom scaled dot-product attention\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(Q_rotated, K_rotated, V, mask)\n",
    "        # print(scaled_attention.shape) # [N, num_heads, seq_len, depth]\n",
    "\n",
    "        # Transpose and reshape back to (batch_size, seq_len, d_model)\n",
    "        scaled_attention = scaled_attention.transpose(1, 2).contiguous() # [N, seq_len, num_heads, depth]\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model) # [N, seq_len, d_model]\n",
    "\n",
    "        # Apply the final linear layer to combine the heads\n",
    "        attn_output = self.Wo(concat_attention) # [N, seq_len, d_model]\n",
    "\n",
    "        # Add & Norm\n",
    "        x = self.layernorm1(x + self.dropout(attn_output)) # # [N, seq_len, d_model]\n",
    "\n",
    "        # Feed-forward\n",
    "        ff_output = self.feed_forward(x) # [N, seq_len, d_model]\n",
    "\n",
    "        # Add & Norm\n",
    "        x = self.layernorm2(x + self.dropout(ff_output)) # [N, seq_len, d_model]\n",
    "\n",
    "        return x # [N, seq_len, d_model]\n",
    "    \n",
    "\n",
    "model = TransformerEncoderLayer(d_model=256, num_heads=8, ff_dim=512)\n",
    "output = model(torch.randn(1, 1000, 256))\n",
    "print(\"output: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size: int, \n",
    "                 d_model: int,\n",
    "                 num_heads: int, \n",
    "                 ff_dim: int, \n",
    "                 output_size: int, \n",
    "                 num_layers: int, \n",
    "                 dropout:float = 0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, \n",
    "                                      embedding_dim=d_model)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model=d_model, num_heads=num_heads, ff_dim=ff_dim) \n",
    "            for _ in range(num_layers)  \n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(in_features=d_model, out_features=output_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x: [N, seq_len]\n",
    "        x = self.embedding(x) # [N, seq_len, embed_dim]\n",
    "        for layer in self.encoder_layers:\n",
    "            x  = layer(x, mask) # [N, seq_len, embed_dim]\n",
    "        x = x.mean(dim=1) # (batch_size, d_model)\n",
    "        x = self.fc(self.dropout(x)) # (batch_size, output_size)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = TransformerModel(vocab_size=100000, d_model=256, \n",
    "                         num_heads=8, ff_dim=512, \n",
    "                         output_size=9, num_layers=2)\n",
    "\n",
    "mock_data = torch.randint(0, 1, (2, 1000), dtype=torch.long)\n",
    "\n",
    "output = model(mock_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataframe: pd.DataFrame, \n",
    "                 tokenizer):\n",
    "        self.titles = dataframe['title'].str.lower().values\n",
    "        self.labels = dataframe['label_numeric'].values\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.titles)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        title = self.titles[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        title_ids = self.tokenizer.encode(title)\n",
    "        return (\n",
    "            torch.tensor(title_ids, dtype=torch.long), \n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collate function to pad sequences\n",
    "def collate_fn(batch):\n",
    "    input_ids = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    max_length = max(len(ids) for ids in input_ids)\n",
    "    input_ids = torch.stack([torch.cat([ids, torch.zeros(max_length - len(ids), dtype=torch.long)]) for ids in input_ids])\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return input_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train_set.csv\")\n",
    "val_df = pd.read_csv(\"./data/validation_set.csv\")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(encoding_name='gpt2')\n",
    "\n",
    "train_dataset = TextDataset(dataframe=train_df, tokenizer=tokenizer)\n",
    "val_dataset = TextDataset(dataframe=val_df, tokenizer=tokenizer)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                              shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                            shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Transformer model\n",
    "vocab_size = tokenizer.n_vocab\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "output_size = len(train_df['label_numeric'].unique())\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "model = TransformerModel(vocab_size=vocab_size, d_model=d_model, \n",
    "                         num_heads=num_heads, ff_dim=ff_dim, output_size=output_size, \n",
    "                         num_layers=num_layers, dropout=dropout)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.8510082364082336\n",
      "Validation Accuracy after Epoch 1: 73.72%\n",
      "Epoch 2/20, Loss: 0.7910841107368469\n",
      "Validation Accuracy after Epoch 2: 78.13%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m----> 4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids)\n\u001b[1;32m      6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:825\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 825\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    for input_ids, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, labels in val_dataloader:\n",
    "            outputs = model(input_ids)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy after Epoch {epoch+1}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
